{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8554b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,  AutoModelForMaskedLM\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset, ClassLabel\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from transformers import DataCollatorWithPadding\n",
    "import evaluate\n",
    "import torch\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acfea5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 25 19:40:44 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    On   | 00000000:4F:00.0 Off |                    0 |\n",
      "| 30%   28C    P8    22W / 300W |      3MiB / 45631MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000    On   | 00000000:52:00.0 Off |                    0 |\n",
      "| 30%   31C    P8    14W / 300W |      3MiB / 45631MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000    On   | 00000000:56:00.0 Off |                  Off |\n",
      "| 30%   37C    P5    70W / 300W |      3MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A6000    On   | 00000000:57:00.0 Off |                  Off |\n",
      "| 30%   31C    P8    22W / 300W |      3MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA RTX A6000    On   | 00000000:CE:00.0 Off |                    0 |\n",
      "| 30%   29C    P8    21W / 300W |      3MiB / 45631MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA RTX A6000    On   | 00000000:D1:00.0 Off |                    0 |\n",
      "| 30%   31C    P8    19W / 300W |      3MiB / 45631MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA RTX A6000    On   | 00000000:D5:00.0 Off |                  Off |\n",
      "| 30%   30C    P8    22W / 300W |      3MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA RTX A6000    On   | 00000000:D6:00.0 Off |                  Off |\n",
      "| 30%   32C    P8    21W / 300W |      3MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b0d21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n",
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "#torch.manual_seed(0)\n",
    "#torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "700aa0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label ={0: \"formal\", 1: \"informal\"}\n",
    "label2id = {\"formal\" : 0, \"informal\" : 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcfb2038",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=2, id2label=id2label, label2id=label2id)\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\", num_labels=2, id2label=id2label, label2id=label2id)\n",
    "#model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\", num_labels=2)\n",
    "\n",
    "#model = AutoModelForMaskedLM.from_pretrained(\"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c0ebcde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-aa4180dfc0d8544e\n",
      "Found cached dataset text (/home/sumire/.cache/huggingface/datasets/text/default-aa4180dfc0d8544e/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf4b168a0a24757bcba4b93f4355fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8d8cb62fa76f7d67\n",
      "Found cached dataset text (/home/sumire/.cache/huggingface/datasets/text/default-8d8cb62fa76f7d67/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61df4ba4aa5a4460908753209fc25aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c5e57c6f711b908f\n",
      "Found cached dataset text (/home/sumire/.cache/huggingface/datasets/text/default-c5e57c6f711b908f/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2854ad85214b82a5fbe9cbbf561947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-606034f57a6cac42\n",
      "Found cached dataset text (/home/sumire/.cache/huggingface/datasets/text/default-606034f57a6cac42/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbed9a12f33e48fa8cbd53071ee99cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-4a02738e5d40d937\n",
      "Found cached dataset text (/home/sumire/.cache/huggingface/datasets/text/default-4a02738e5d40d937/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb47f46e86b946eaa2053d597b6459ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-483622c8cf9f8077\n",
      "Found cached dataset text (/home/sumire/.cache/huggingface/datasets/text/default-483622c8cf9f8077/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be9eef7fd95413eb90e50a53852e1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Annotate Data and Shuffle\n",
    "hon_data_path = \"/home/sumire/thesis/LLM_Contextual_Prompt_MT/data/contrastive-controlled-mt/IWSLT2022/data/\"\n",
    "\n",
    "train1_fp_f = hon_data_path + \"train/en-ja/formality-control.train.telephony.en-ja.formal.ja\"\n",
    "train1_fp_if = hon_data_path + \"train/en-ja/formality-control.train.telephony.en-ja.informal.ja\"\n",
    "train2_fp_f = hon_data_path + \"train/en-ja/formality-control.train.topical-chat.en-ja.formal.ja\"\n",
    "train2_fp_if = hon_data_path + \"train/en-ja/formality-control.train.topical-chat.en-ja.informal.ja\"\n",
    "\n",
    "test_fp_f = hon_data_path + \"test/en-ja/formality-control.test.en-ja.formal.ja\"\n",
    "test_fp_if = hon_data_path + \"test/en-ja/formality-control.test.en-ja.informal.ja\"\n",
    "\n",
    "train_with_label = []\n",
    "test_with_label = []\n",
    "\n",
    "for fp in [train1_fp_f, train1_fp_if, train2_fp_f, train2_fp_if, test_fp_f, test_fp_if]: \n",
    "    dataset = load_dataset(\"text\", data_files=fp)\n",
    "    \n",
    "    if fp == train1_fp_f or fp == train2_fp_f:\n",
    "        for sent in dataset[\"train\"][\"text\"]:\n",
    "            sent = sent + \", 0\" \n",
    "            train_with_label.append(sent)\n",
    "    \n",
    "    elif fp == train1_fp_if or fp == train2_fp_if:\n",
    "        for sent in dataset[\"train\"][\"text\"]:\n",
    "            sent = sent + \", 1\"\n",
    "            train_with_label.append(sent)\n",
    "            \n",
    "    elif fp == test_fp_f :\n",
    "        for sent in dataset[\"train\"][\"text\"]:\n",
    "            sent = sent + \", 0\"\n",
    "            test_with_label.append(sent)\n",
    "    \n",
    "    elif fp == test_fp_if :\n",
    "        for sent in dataset[\"train\"][\"text\"]:\n",
    "            sent = sent + \", 1\"\n",
    "            test_with_label.append(sent)\n",
    "\n",
    "random.shuffle(train_with_label)\n",
    "random.shuffle(test_with_label)\n",
    "\n",
    "with open (hon_data_path + \"modified/train_en-ja.ja\", \"w\") as train_file:\n",
    "    for item in train_with_label:\n",
    "        # write each item on a new line\n",
    "        train_file.write(\"%s\\n\" % item)\n",
    "        \n",
    "with open (hon_data_path + \"modified/test_en-ja.ja\", \"w\") as test_file:\n",
    "    for item in test_with_label:\n",
    "        # write each item on a new line\n",
    "        test_file.write(\"%s\\n\" % item)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cf8f940",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_with_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[43mtest_with_label\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_with_label' is not defined"
     ]
    }
   ],
   "source": [
    "print (len(test_with_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "149d2fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0a2611c093b6474c\n",
      "Found cached dataset text (/home/sumire/.cache/huggingface/datasets/text/default-0a2611c093b6474c/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142e7806100d40f0a6e4a1778e0d58c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1188\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_lang = \"ja\"\n",
    "hon_data_path = \"/home/sumire/thesis/LLM_Contextual_Prompt_MT/data/contrastive-controlled-mt/IWSLT2022/data/\"\n",
    "\n",
    "data_files = { \"train\": hon_data_path+\"modified/train_en-ja.ja\", \"test\": hon_data_path+\"modified/test_en-ja.ja\"}\n",
    "dataset = load_dataset(\"text\", data_files=data_files)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7956403",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs =  [sent.split(\", \")[0] for sent in dataset[\"test\"][\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40d420c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add labels\n",
    "train_labels = [sent.split(\", \")[1] for sent in dataset[\"train\"][\"text\"]]\n",
    "test_labels = [sent.split(\", \")[1] for sent in dataset[\"test\"][\"text\"]]\n",
    "\n",
    "dataset[\"train\"]=dataset[\"train\"].add_column(\"labels\", train_labels)\n",
    "dataset[\"test\"]=dataset[\"test\"].add_column(\"labels\", test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a159d96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 1188\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4258a855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/sumire/.cache/huggingface/datasets/text/default-0a2611c093b6474c/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c/cache-53c785a19aaad065.arrow\n",
      "Loading cached processed dataset at /home/sumire/.cache/huggingface/datasets/text/default-0a2611c093b6474c/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c/cache-b49de0a535926365.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'labels': ClassLabel(names=['0', '1'], id=None)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset = dataset.cast_column('labels', ClassLabel(num_classes=2, names=[\"Formal\", \"Informal\"]))\n",
    "dataset = dataset.class_encode_column('labels')\n",
    "dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b27fc93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'私は買い物の9割をそこでしていますが、ある種類の紙や特定のレシピのために探してもない商品もある。'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0][\"text\"].split(\", \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3343c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(data):\n",
    "    inputs = [sent.split(\", \")[0] for sent in data[\"text\"]]\n",
    "    #inputs = [kshot + sent + ' = ' for doc in data[\"doc\"] for sent in doc[\"en\"] ][:50]\n",
    "    return tokenizer(inputs, truncation=True, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ab70b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/sumire/.cache/huggingface/datasets/text/default-0a2611c093b6474c/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c/cache-5f2e070f77bc0c75.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a579411182444aa5bab2887af288f785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed45333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    \n",
    "    preds, labels = eval_preds\n",
    "    #eval_preds[1] = [label for label in data[\"labels\"]]\n",
    "    #preds = eval_preds[1]\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    f1 = evaluate.load(\"f1\")\n",
    "    \n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    result = {}\n",
    "    result[\"accuracy\"] = accuracy.compute(predictions=preds, references=labels)\n",
    "    result[\"f1\"] = f1.compute(predictions=preds, references=labels)\n",
    "    print (result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "679eae7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `XLMRobertaForMaskedLM.forward` and have been ignored: text. If text are not expected by `XLMRobertaForMaskedLM.forward`,  you can safely ignore this message.\n",
      "/home/sumire/miniconda3/envs/llm_mt/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2000\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 250\n",
      "  Number of trainable parameters = 278295186\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (1440) to match target batch_size (16).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results/hon_xlm-r\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     15\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     16\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_mt/lib/python3.8/site-packages/transformers/trainer.py:1527\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1524\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1526\u001b[0m )\n\u001b[0;32m-> 1527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_mt/lib/python3.8/site-packages/transformers/trainer.py:1775\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1773\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1778\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1780\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_mt/lib/python3.8/site-packages/transformers/trainer.py:2523\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2523\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2526\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_mt/lib/python3.8/site-packages/transformers/trainer.py:2555\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2554\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2555\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2556\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2557\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_mt/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_mt/lib/python3.8/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:1127\u001b[0m, in \u001b[0;36mXLMRobertaForMaskedLM.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1126\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m-> 1127\u001b[0m     masked_lm_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction_scores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1130\u001b[0m     output \u001b[38;5;241m=\u001b[39m (prediction_scores,) \u001b[38;5;241m+\u001b[39m outputs[\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_mt/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_mt/lib/python3.8/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_mt/lib/python3.8/site-packages/torch/nn/functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (1440) to match target batch_size (16)."
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/hon_xlm-r\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a3ba91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/sumire/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/sumire/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/sumire/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/pytorch_model.bin\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at /home/sumire/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading file sentencepiece.bpe.model from cache at /home/sumire/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at /home/sumire/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /home/sumire/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.5117709040641785},\n",
       " {'label': 'LABEL_0', 'score': 0.5132048726081848},\n",
       " {'label': 'LABEL_0', 'score': 0.5131912231445312},\n",
       " {'label': 'LABEL_0', 'score': 0.503860354423523},\n",
       " {'label': 'LABEL_0', 'score': 0.5126904249191284},\n",
       " {'label': 'LABEL_0', 'score': 0.5159482359886169},\n",
       " {'label': 'LABEL_0', 'score': 0.5020590424537659},\n",
       " {'label': 'LABEL_0', 'score': 0.5043507218360901},\n",
       " {'label': 'LABEL_0', 'score': 0.5159978270530701},\n",
       " {'label': 'LABEL_0', 'score': 0.5094629526138306},\n",
       " {'label': 'LABEL_0', 'score': 0.5092950463294983},\n",
       " {'label': 'LABEL_0', 'score': 0.5163185000419617},\n",
       " {'label': 'LABEL_0', 'score': 0.5007461309432983},\n",
       " {'label': 'LABEL_0', 'score': 0.510414183139801},\n",
       " {'label': 'LABEL_0', 'score': 0.5141968131065369},\n",
       " {'label': 'LABEL_0', 'score': 0.5049339532852173},\n",
       " {'label': 'LABEL_0', 'score': 0.5119562149047852},\n",
       " {'label': 'LABEL_0', 'score': 0.5134588479995728},\n",
       " {'label': 'LABEL_0', 'score': 0.5119021534919739},\n",
       " {'label': 'LABEL_0', 'score': 0.5113539695739746},\n",
       " {'label': 'LABEL_0', 'score': 0.5119016766548157},\n",
       " {'label': 'LABEL_0', 'score': 0.5108177065849304},\n",
       " {'label': 'LABEL_0', 'score': 0.5123927593231201},\n",
       " {'label': 'LABEL_0', 'score': 0.5095105767250061},\n",
       " {'label': 'LABEL_1', 'score': 0.5004915595054626},\n",
       " {'label': 'LABEL_0', 'score': 0.5036477446556091},\n",
       " {'label': 'LABEL_0', 'score': 0.5069076418876648},\n",
       " {'label': 'LABEL_0', 'score': 0.5092563033103943},\n",
       " {'label': 'LABEL_0', 'score': 0.5120704174041748},\n",
       " {'label': 'LABEL_0', 'score': 0.5086477994918823},\n",
       " {'label': 'LABEL_0', 'score': 0.5123857259750366},\n",
       " {'label': 'LABEL_0', 'score': 0.5138046741485596},\n",
       " {'label': 'LABEL_0', 'score': 0.506637692451477},\n",
       " {'label': 'LABEL_0', 'score': 0.5065343976020813},\n",
       " {'label': 'LABEL_0', 'score': 0.504278838634491},\n",
       " {'label': 'LABEL_0', 'score': 0.5081695914268494},\n",
       " {'label': 'LABEL_0', 'score': 0.5084792971611023},\n",
       " {'label': 'LABEL_0', 'score': 0.5099065899848938},\n",
       " {'label': 'LABEL_0', 'score': 0.5139826536178589},\n",
       " {'label': 'LABEL_0', 'score': 0.513970136642456},\n",
       " {'label': 'LABEL_0', 'score': 0.5091344714164734},\n",
       " {'label': 'LABEL_0', 'score': 0.5034173727035522},\n",
       " {'label': 'LABEL_0', 'score': 0.511959969997406},\n",
       " {'label': 'LABEL_0', 'score': 0.5095313787460327},\n",
       " {'label': 'LABEL_0', 'score': 0.5094289779663086},\n",
       " {'label': 'LABEL_0', 'score': 0.5103076696395874},\n",
       " {'label': 'LABEL_1', 'score': 0.5097717046737671},\n",
       " {'label': 'LABEL_0', 'score': 0.501072347164154},\n",
       " {'label': 'LABEL_0', 'score': 0.5128980278968811},\n",
       " {'label': 'LABEL_0', 'score': 0.5080810785293579},\n",
       " {'label': 'LABEL_0', 'score': 0.5058609843254089},\n",
       " {'label': 'LABEL_0', 'score': 0.5092453956604004},\n",
       " {'label': 'LABEL_0', 'score': 0.5141912698745728},\n",
       " {'label': 'LABEL_0', 'score': 0.5075702667236328},\n",
       " {'label': 'LABEL_0', 'score': 0.5049949288368225},\n",
       " {'label': 'LABEL_0', 'score': 0.5030556917190552},\n",
       " {'label': 'LABEL_0', 'score': 0.5103647708892822},\n",
       " {'label': 'LABEL_0', 'score': 0.5073092579841614},\n",
       " {'label': 'LABEL_1', 'score': 0.5013706088066101},\n",
       " {'label': 'LABEL_0', 'score': 0.5137974619865417},\n",
       " {'label': 'LABEL_0', 'score': 0.5146126747131348},\n",
       " {'label': 'LABEL_0', 'score': 0.5054530501365662},\n",
       " {'label': 'LABEL_0', 'score': 0.5061572790145874},\n",
       " {'label': 'LABEL_0', 'score': 0.5059919953346252},\n",
       " {'label': 'LABEL_0', 'score': 0.5105828642845154},\n",
       " {'label': 'LABEL_0', 'score': 0.5129661560058594},\n",
       " {'label': 'LABEL_0', 'score': 0.5073260068893433},\n",
       " {'label': 'LABEL_0', 'score': 0.5111545920372009},\n",
       " {'label': 'LABEL_0', 'score': 0.5168076157569885},\n",
       " {'label': 'LABEL_0', 'score': 0.5103127956390381},\n",
       " {'label': 'LABEL_0', 'score': 0.5105957984924316},\n",
       " {'label': 'LABEL_0', 'score': 0.5023982524871826},\n",
       " {'label': 'LABEL_0', 'score': 0.5031478404998779},\n",
       " {'label': 'LABEL_0', 'score': 0.5144080519676208},\n",
       " {'label': 'LABEL_0', 'score': 0.5059805512428284},\n",
       " {'label': 'LABEL_0', 'score': 0.5094914436340332},\n",
       " {'label': 'LABEL_0', 'score': 0.5130897164344788},\n",
       " {'label': 'LABEL_0', 'score': 0.5105575323104858},\n",
       " {'label': 'LABEL_0', 'score': 0.5121269822120667},\n",
       " {'label': 'LABEL_0', 'score': 0.5054837465286255},\n",
       " {'label': 'LABEL_0', 'score': 0.5081338882446289},\n",
       " {'label': 'LABEL_0', 'score': 0.5155031085014343},\n",
       " {'label': 'LABEL_0', 'score': 0.5044254660606384},\n",
       " {'label': 'LABEL_0', 'score': 0.5102663636207581},\n",
       " {'label': 'LABEL_0', 'score': 0.5102158784866333},\n",
       " {'label': 'LABEL_1', 'score': 0.5001915693283081},\n",
       " {'label': 'LABEL_0', 'score': 0.5098872780799866},\n",
       " {'label': 'LABEL_0', 'score': 0.5063348412513733},\n",
       " {'label': 'LABEL_0', 'score': 0.5123494863510132},\n",
       " {'label': 'LABEL_0', 'score': 0.5037439465522766},\n",
       " {'label': 'LABEL_0', 'score': 0.5090150833129883},\n",
       " {'label': 'LABEL_0', 'score': 0.5114807486534119},\n",
       " {'label': 'LABEL_0', 'score': 0.5108903646469116},\n",
       " {'label': 'LABEL_0', 'score': 0.5093748569488525},\n",
       " {'label': 'LABEL_0', 'score': 0.507165789604187},\n",
       " {'label': 'LABEL_1', 'score': 0.5005903244018555},\n",
       " {'label': 'LABEL_0', 'score': 0.5156571269035339},\n",
       " {'label': 'LABEL_0', 'score': 0.510914146900177},\n",
       " {'label': 'LABEL_0', 'score': 0.5098915100097656},\n",
       " {'label': 'LABEL_0', 'score': 0.5132257342338562},\n",
       " {'label': 'LABEL_0', 'score': 0.5011535882949829},\n",
       " {'label': 'LABEL_0', 'score': 0.5119354724884033},\n",
       " {'label': 'LABEL_0', 'score': 0.5144609212875366},\n",
       " {'label': 'LABEL_0', 'score': 0.5111557245254517},\n",
       " {'label': 'LABEL_0', 'score': 0.5064471364021301},\n",
       " {'label': 'LABEL_0', 'score': 0.5088468194007874},\n",
       " {'label': 'LABEL_0', 'score': 0.5111889243125916},\n",
       " {'label': 'LABEL_0', 'score': 0.5089321136474609},\n",
       " {'label': 'LABEL_0', 'score': 0.5017518401145935},\n",
       " {'label': 'LABEL_0', 'score': 0.5106920599937439},\n",
       " {'label': 'LABEL_0', 'score': 0.5019286870956421},\n",
       " {'label': 'LABEL_0', 'score': 0.508332371711731},\n",
       " {'label': 'LABEL_0', 'score': 0.5059707164764404},\n",
       " {'label': 'LABEL_0', 'score': 0.508770227432251},\n",
       " {'label': 'LABEL_1', 'score': 0.503075122833252},\n",
       " {'label': 'LABEL_0', 'score': 0.5064017176628113},\n",
       " {'label': 'LABEL_0', 'score': 0.5109859704971313},\n",
       " {'label': 'LABEL_0', 'score': 0.5078775882720947},\n",
       " {'label': 'LABEL_0', 'score': 0.5087602734565735},\n",
       " {'label': 'LABEL_0', 'score': 0.5130860209465027},\n",
       " {'label': 'LABEL_0', 'score': 0.5094268321990967},\n",
       " {'label': 'LABEL_0', 'score': 0.5095100402832031},\n",
       " {'label': 'LABEL_0', 'score': 0.5074183344841003},\n",
       " {'label': 'LABEL_0', 'score': 0.5127903819084167},\n",
       " {'label': 'LABEL_0', 'score': 0.5038208961486816},\n",
       " {'label': 'LABEL_0', 'score': 0.5082092881202698},\n",
       " {'label': 'LABEL_0', 'score': 0.5083620548248291},\n",
       " {'label': 'LABEL_0', 'score': 0.5120112299919128},\n",
       " {'label': 'LABEL_0', 'score': 0.5096160173416138},\n",
       " {'label': 'LABEL_0', 'score': 0.5118961930274963},\n",
       " {'label': 'LABEL_0', 'score': 0.5099919438362122},\n",
       " {'label': 'LABEL_0', 'score': 0.5071468353271484},\n",
       " {'label': 'LABEL_0', 'score': 0.5062860250473022},\n",
       " {'label': 'LABEL_0', 'score': 0.5129756927490234},\n",
       " {'label': 'LABEL_0', 'score': 0.5125234127044678},\n",
       " {'label': 'LABEL_0', 'score': 0.5137879252433777},\n",
       " {'label': 'LABEL_0', 'score': 0.5084142088890076},\n",
       " {'label': 'LABEL_0', 'score': 0.5088404417037964},\n",
       " {'label': 'LABEL_0', 'score': 0.5077574849128723},\n",
       " {'label': 'LABEL_0', 'score': 0.512327253818512},\n",
       " {'label': 'LABEL_0', 'score': 0.5101997256278992},\n",
       " {'label': 'LABEL_0', 'score': 0.5037114024162292},\n",
       " {'label': 'LABEL_0', 'score': 0.5086597800254822},\n",
       " {'label': 'LABEL_0', 'score': 0.5069791078567505},\n",
       " {'label': 'LABEL_0', 'score': 0.5068076252937317},\n",
       " {'label': 'LABEL_0', 'score': 0.5127326250076294},\n",
       " {'label': 'LABEL_0', 'score': 0.5103241205215454},\n",
       " {'label': 'LABEL_0', 'score': 0.512411892414093},\n",
       " {'label': 'LABEL_0', 'score': 0.5029845237731934},\n",
       " {'label': 'LABEL_0', 'score': 0.5020996332168579},\n",
       " {'label': 'LABEL_0', 'score': 0.5117788910865784},\n",
       " {'label': 'LABEL_0', 'score': 0.5089558959007263},\n",
       " {'label': 'LABEL_0', 'score': 0.5067732930183411},\n",
       " {'label': 'LABEL_0', 'score': 0.5124663710594177},\n",
       " {'label': 'LABEL_0', 'score': 0.5090142488479614},\n",
       " {'label': 'LABEL_0', 'score': 0.5047531127929688},\n",
       " {'label': 'LABEL_0', 'score': 0.5074567794799805},\n",
       " {'label': 'LABEL_0', 'score': 0.5087612271308899},\n",
       " {'label': 'LABEL_0', 'score': 0.5081290602684021},\n",
       " {'label': 'LABEL_0', 'score': 0.5024111866950989},\n",
       " {'label': 'LABEL_0', 'score': 0.513413667678833},\n",
       " {'label': 'LABEL_0', 'score': 0.5130600929260254},\n",
       " {'label': 'LABEL_0', 'score': 0.5101959705352783},\n",
       " {'label': 'LABEL_0', 'score': 0.5092827081680298},\n",
       " {'label': 'LABEL_0', 'score': 0.5144023895263672},\n",
       " {'label': 'LABEL_0', 'score': 0.5086522102355957},\n",
       " {'label': 'LABEL_0', 'score': 0.5106695890426636},\n",
       " {'label': 'LABEL_0', 'score': 0.5115392208099365},\n",
       " {'label': 'LABEL_0', 'score': 0.5092567205429077},\n",
       " {'label': 'LABEL_0', 'score': 0.5148244500160217},\n",
       " {'label': 'LABEL_0', 'score': 0.5104756355285645},\n",
       " {'label': 'LABEL_0', 'score': 0.5025942325592041},\n",
       " {'label': 'LABEL_0', 'score': 0.5091249346733093},\n",
       " {'label': 'LABEL_0', 'score': 0.5107637643814087},\n",
       " {'label': 'LABEL_0', 'score': 0.5045310854911804},\n",
       " {'label': 'LABEL_0', 'score': 0.507742702960968},\n",
       " {'label': 'LABEL_0', 'score': 0.5037838816642761},\n",
       " {'label': 'LABEL_0', 'score': 0.5125836133956909},\n",
       " {'label': 'LABEL_0', 'score': 0.5121301412582397},\n",
       " {'label': 'LABEL_0', 'score': 0.5091486573219299},\n",
       " {'label': 'LABEL_0', 'score': 0.5028820037841797},\n",
       " {'label': 'LABEL_0', 'score': 0.5083374977111816},\n",
       " {'label': 'LABEL_0', 'score': 0.5091859698295593},\n",
       " {'label': 'LABEL_0', 'score': 0.5134257078170776},\n",
       " {'label': 'LABEL_0', 'score': 0.5050565600395203},\n",
       " {'label': 'LABEL_0', 'score': 0.513802707195282},\n",
       " {'label': 'LABEL_0', 'score': 0.5085846185684204},\n",
       " {'label': 'LABEL_1', 'score': 0.501462459564209},\n",
       " {'label': 'LABEL_0', 'score': 0.5064391493797302},\n",
       " {'label': 'LABEL_0', 'score': 0.5081949234008789},\n",
       " {'label': 'LABEL_0', 'score': 0.5133317112922668},\n",
       " {'label': 'LABEL_0', 'score': 0.5102589726448059},\n",
       " {'label': 'LABEL_0', 'score': 0.5104844570159912},\n",
       " {'label': 'LABEL_0', 'score': 0.5054069757461548},\n",
       " {'label': 'LABEL_0', 'score': 0.5075198411941528},\n",
       " {'label': 'LABEL_0', 'score': 0.506349503993988},\n",
       " {'label': 'LABEL_0', 'score': 0.5122923254966736},\n",
       " {'label': 'LABEL_0', 'score': 0.5022324919700623},\n",
       " {'label': 'LABEL_0', 'score': 0.5127173662185669},\n",
       " {'label': 'LABEL_0', 'score': 0.5137700438499451},\n",
       " {'label': 'LABEL_0', 'score': 0.5101652145385742},\n",
       " {'label': 'LABEL_0', 'score': 0.5050523281097412},\n",
       " {'label': 'LABEL_0', 'score': 0.5106450915336609},\n",
       " {'label': 'LABEL_1', 'score': 0.5079951286315918},\n",
       " {'label': 'LABEL_0', 'score': 0.5148465037345886},\n",
       " {'label': 'LABEL_0', 'score': 0.5059026479721069},\n",
       " {'label': 'LABEL_0', 'score': 0.5095235705375671},\n",
       " {'label': 'LABEL_0', 'score': 0.5124446153640747},\n",
       " {'label': 'LABEL_0', 'score': 0.5054518580436707},\n",
       " {'label': 'LABEL_0', 'score': 0.51174396276474},\n",
       " {'label': 'LABEL_0', 'score': 0.5081089735031128},\n",
       " {'label': 'LABEL_0', 'score': 0.5073357224464417},\n",
       " {'label': 'LABEL_0', 'score': 0.505517303943634},\n",
       " {'label': 'LABEL_0', 'score': 0.5120663046836853},\n",
       " {'label': 'LABEL_0', 'score': 0.513850748538971},\n",
       " {'label': 'LABEL_0', 'score': 0.5096767544746399},\n",
       " {'label': 'LABEL_0', 'score': 0.5069082379341125},\n",
       " {'label': 'LABEL_0', 'score': 0.514448344707489},\n",
       " {'label': 'LABEL_0', 'score': 0.5134538412094116},\n",
       " {'label': 'LABEL_0', 'score': 0.5101997256278992},\n",
       " {'label': 'LABEL_0', 'score': 0.5111969709396362},\n",
       " {'label': 'LABEL_0', 'score': 0.500621497631073},\n",
       " {'label': 'LABEL_0', 'score': 0.5110968947410583},\n",
       " {'label': 'LABEL_0', 'score': 0.5080395340919495},\n",
       " {'label': 'LABEL_0', 'score': 0.5107084512710571},\n",
       " {'label': 'LABEL_0', 'score': 0.514244019985199},\n",
       " {'label': 'LABEL_0', 'score': 0.511690616607666},\n",
       " {'label': 'LABEL_0', 'score': 0.50831538438797},\n",
       " {'label': 'LABEL_0', 'score': 0.5123583674430847},\n",
       " {'label': 'LABEL_0', 'score': 0.5083350539207458},\n",
       " {'label': 'LABEL_0', 'score': 0.5100731253623962},\n",
       " {'label': 'LABEL_0', 'score': 0.5045468211174011},\n",
       " {'label': 'LABEL_0', 'score': 0.5119868516921997},\n",
       " {'label': 'LABEL_0', 'score': 0.5017306804656982},\n",
       " {'label': 'LABEL_0', 'score': 0.5086168646812439},\n",
       " {'label': 'LABEL_0', 'score': 0.5110303163528442},\n",
       " {'label': 'LABEL_0', 'score': 0.5138339400291443},\n",
       " {'label': 'LABEL_0', 'score': 0.512279748916626},\n",
       " {'label': 'LABEL_0', 'score': 0.5072876214981079},\n",
       " {'label': 'LABEL_0', 'score': 0.5041634440422058},\n",
       " {'label': 'LABEL_0', 'score': 0.5119597911834717},\n",
       " {'label': 'LABEL_0', 'score': 0.5014787912368774},\n",
       " {'label': 'LABEL_0', 'score': 0.5077269077301025},\n",
       " {'label': 'LABEL_0', 'score': 0.5126582980155945},\n",
       " {'label': 'LABEL_0', 'score': 0.5039752721786499},\n",
       " {'label': 'LABEL_0', 'score': 0.5119649767875671},\n",
       " {'label': 'LABEL_0', 'score': 0.5083124041557312},\n",
       " {'label': 'LABEL_0', 'score': 0.5094122886657715},\n",
       " {'label': 'LABEL_0', 'score': 0.5115230083465576},\n",
       " {'label': 'LABEL_0', 'score': 0.513161838054657},\n",
       " {'label': 'LABEL_0', 'score': 0.5109943747520447},\n",
       " {'label': 'LABEL_0', 'score': 0.5057029724121094},\n",
       " {'label': 'LABEL_0', 'score': 0.5119803547859192},\n",
       " {'label': 'LABEL_0', 'score': 0.505881667137146},\n",
       " {'label': 'LABEL_0', 'score': 0.5105680227279663},\n",
       " {'label': 'LABEL_0', 'score': 0.5120384693145752},\n",
       " {'label': 'LABEL_0', 'score': 0.5045968294143677},\n",
       " {'label': 'LABEL_0', 'score': 0.5090653896331787},\n",
       " {'label': 'LABEL_0', 'score': 0.5080665946006775},\n",
       " {'label': 'LABEL_0', 'score': 0.5154194831848145},\n",
       " {'label': 'LABEL_0', 'score': 0.5105745196342468},\n",
       " {'label': 'LABEL_0', 'score': 0.5136814117431641},\n",
       " {'label': 'LABEL_0', 'score': 0.5092131495475769},\n",
       " {'label': 'LABEL_1', 'score': 0.5013213753700256},\n",
       " {'label': 'LABEL_0', 'score': 0.5120986700057983},\n",
       " {'label': 'LABEL_0', 'score': 0.512628436088562},\n",
       " {'label': 'LABEL_0', 'score': 0.506698727607727},\n",
       " {'label': 'LABEL_0', 'score': 0.5053935647010803},\n",
       " {'label': 'LABEL_0', 'score': 0.5100225210189819},\n",
       " {'label': 'LABEL_0', 'score': 0.508854866027832},\n",
       " {'label': 'LABEL_0', 'score': 0.5101047158241272},\n",
       " {'label': 'LABEL_0', 'score': 0.5091084837913513},\n",
       " {'label': 'LABEL_0', 'score': 0.5068551898002625},\n",
       " {'label': 'LABEL_0', 'score': 0.510047197341919},\n",
       " {'label': 'LABEL_0', 'score': 0.5075957179069519},\n",
       " {'label': 'LABEL_0', 'score': 0.507793664932251},\n",
       " {'label': 'LABEL_0', 'score': 0.5112273097038269},\n",
       " {'label': 'LABEL_0', 'score': 0.509271502494812},\n",
       " {'label': 'LABEL_0', 'score': 0.5026394724845886},\n",
       " {'label': 'LABEL_0', 'score': 0.5074703097343445},\n",
       " {'label': 'LABEL_0', 'score': 0.5097890496253967},\n",
       " {'label': 'LABEL_0', 'score': 0.5150673389434814},\n",
       " {'label': 'LABEL_0', 'score': 0.5070197582244873},\n",
       " {'label': 'LABEL_0', 'score': 0.5088988542556763},\n",
       " {'label': 'LABEL_0', 'score': 0.5168653726577759},\n",
       " {'label': 'LABEL_0', 'score': 0.5085837841033936},\n",
       " {'label': 'LABEL_0', 'score': 0.5103958249092102},\n",
       " {'label': 'LABEL_0', 'score': 0.5091540813446045},\n",
       " {'label': 'LABEL_0', 'score': 0.5080791711807251},\n",
       " {'label': 'LABEL_0', 'score': 0.5150988101959229},\n",
       " {'label': 'LABEL_0', 'score': 0.5088085532188416},\n",
       " {'label': 'LABEL_0', 'score': 0.5017357468605042},\n",
       " {'label': 'LABEL_0', 'score': 0.5066577196121216},\n",
       " {'label': 'LABEL_0', 'score': 0.5144432187080383},\n",
       " {'label': 'LABEL_1', 'score': 0.5008737444877625},\n",
       " {'label': 'LABEL_0', 'score': 0.5138117671012878},\n",
       " {'label': 'LABEL_0', 'score': 0.5127208232879639},\n",
       " {'label': 'LABEL_0', 'score': 0.5100405216217041},\n",
       " {'label': 'LABEL_0', 'score': 0.510147750377655},\n",
       " {'label': 'LABEL_0', 'score': 0.5058171153068542},\n",
       " {'label': 'LABEL_0', 'score': 0.5126610994338989},\n",
       " {'label': 'LABEL_0', 'score': 0.5156115293502808},\n",
       " {'label': 'LABEL_0', 'score': 0.50151526927948},\n",
       " {'label': 'LABEL_0', 'score': 0.5128066539764404},\n",
       " {'label': 'LABEL_0', 'score': 0.5107460021972656},\n",
       " {'label': 'LABEL_0', 'score': 0.511039674282074},\n",
       " {'label': 'LABEL_0', 'score': 0.5097513794898987},\n",
       " {'label': 'LABEL_0', 'score': 0.513202428817749},\n",
       " {'label': 'LABEL_0', 'score': 0.5091683268547058},\n",
       " {'label': 'LABEL_0', 'score': 0.5053155422210693},\n",
       " {'label': 'LABEL_0', 'score': 0.5136412382125854},\n",
       " {'label': 'LABEL_0', 'score': 0.5114540457725525},\n",
       " {'label': 'LABEL_0', 'score': 0.5091469287872314},\n",
       " {'label': 'LABEL_0', 'score': 0.5090741515159607},\n",
       " {'label': 'LABEL_0', 'score': 0.512480616569519},\n",
       " {'label': 'LABEL_0', 'score': 0.5139216780662537},\n",
       " {'label': 'LABEL_1', 'score': 0.5007932186126709},\n",
       " {'label': 'LABEL_0', 'score': 0.5013872385025024},\n",
       " {'label': 'LABEL_1', 'score': 0.5001848340034485},\n",
       " {'label': 'LABEL_0', 'score': 0.5061226487159729},\n",
       " {'label': 'LABEL_0', 'score': 0.5127695798873901},\n",
       " {'label': 'LABEL_0', 'score': 0.5076166987419128},\n",
       " {'label': 'LABEL_0', 'score': 0.507125735282898},\n",
       " {'label': 'LABEL_0', 'score': 0.5154455900192261},\n",
       " {'label': 'LABEL_0', 'score': 0.5139897465705872},\n",
       " {'label': 'LABEL_0', 'score': 0.5103328227996826},\n",
       " {'label': 'LABEL_0', 'score': 0.510200023651123},\n",
       " {'label': 'LABEL_0', 'score': 0.5120299458503723},\n",
       " {'label': 'LABEL_0', 'score': 0.5113322138786316},\n",
       " {'label': 'LABEL_0', 'score': 0.5116814970970154},\n",
       " {'label': 'LABEL_0', 'score': 0.5066734552383423},\n",
       " {'label': 'LABEL_0', 'score': 0.5090891718864441},\n",
       " {'label': 'LABEL_0', 'score': 0.507726788520813},\n",
       " {'label': 'LABEL_0', 'score': 0.5039751529693604},\n",
       " {'label': 'LABEL_0', 'score': 0.5173367261886597},\n",
       " {'label': 'LABEL_0', 'score': 0.5108675956726074},\n",
       " {'label': 'LABEL_0', 'score': 0.5151796936988831},\n",
       " {'label': 'LABEL_0', 'score': 0.5116638541221619},\n",
       " {'label': 'LABEL_0', 'score': 0.5083634853363037},\n",
       " {'label': 'LABEL_0', 'score': 0.5098077058792114},\n",
       " {'label': 'LABEL_0', 'score': 0.5097863078117371},\n",
       " {'label': 'LABEL_0', 'score': 0.5104096531867981},\n",
       " {'label': 'LABEL_0', 'score': 0.513903796672821},\n",
       " {'label': 'LABEL_0', 'score': 0.5092834830284119},\n",
       " {'label': 'LABEL_0', 'score': 0.5060588121414185},\n",
       " {'label': 'LABEL_0', 'score': 0.5058920979499817},\n",
       " {'label': 'LABEL_1', 'score': 0.5015988945960999},\n",
       " {'label': 'LABEL_0', 'score': 0.5091887712478638},\n",
       " {'label': 'LABEL_0', 'score': 0.5098487734794617},\n",
       " {'label': 'LABEL_0', 'score': 0.5100169777870178},\n",
       " {'label': 'LABEL_0', 'score': 0.500418484210968},\n",
       " {'label': 'LABEL_0', 'score': 0.5067371726036072},\n",
       " {'label': 'LABEL_0', 'score': 0.511107325553894},\n",
       " {'label': 'LABEL_1', 'score': 0.5000920295715332},\n",
       " {'label': 'LABEL_0', 'score': 0.517163872718811},\n",
       " {'label': 'LABEL_1', 'score': 0.5047711133956909},\n",
       " {'label': 'LABEL_0', 'score': 0.5094903111457825},\n",
       " {'label': 'LABEL_0', 'score': 0.5054523348808289},\n",
       " {'label': 'LABEL_0', 'score': 0.5081412196159363},\n",
       " {'label': 'LABEL_0', 'score': 0.5109553337097168},\n",
       " {'label': 'LABEL_0', 'score': 0.5069243311882019},\n",
       " {'label': 'LABEL_0', 'score': 0.5103558301925659},\n",
       " {'label': 'LABEL_0', 'score': 0.5108433961868286},\n",
       " {'label': 'LABEL_0', 'score': 0.5015323162078857},\n",
       " {'label': 'LABEL_0', 'score': 0.516360878944397},\n",
       " {'label': 'LABEL_0', 'score': 0.5051587224006653},\n",
       " {'label': 'LABEL_0', 'score': 0.5139666795730591},\n",
       " {'label': 'LABEL_0', 'score': 0.5067607760429382},\n",
       " {'label': 'LABEL_0', 'score': 0.5012356638908386},\n",
       " {'label': 'LABEL_0', 'score': 0.5004740357398987},\n",
       " {'label': 'LABEL_0', 'score': 0.5050724148750305},\n",
       " {'label': 'LABEL_0', 'score': 0.5139850378036499},\n",
       " {'label': 'LABEL_0', 'score': 0.5116825699806213},\n",
       " {'label': 'LABEL_0', 'score': 0.5089322924613953},\n",
       " {'label': 'LABEL_0', 'score': 0.5138379335403442},\n",
       " {'label': 'LABEL_0', 'score': 0.5118559002876282},\n",
       " {'label': 'LABEL_0', 'score': 0.5116859078407288},\n",
       " {'label': 'LABEL_0', 'score': 0.5129584074020386},\n",
       " {'label': 'LABEL_0', 'score': 0.5079828500747681},\n",
       " {'label': 'LABEL_0', 'score': 0.5150561928749084},\n",
       " {'label': 'LABEL_0', 'score': 0.5038738250732422},\n",
       " {'label': 'LABEL_0', 'score': 0.5115114450454712},\n",
       " {'label': 'LABEL_0', 'score': 0.5112358331680298},\n",
       " {'label': 'LABEL_1', 'score': 0.5007970333099365},\n",
       " {'label': 'LABEL_0', 'score': 0.508362352848053},\n",
       " {'label': 'LABEL_0', 'score': 0.510577917098999},\n",
       " {'label': 'LABEL_1', 'score': 0.5104725360870361},\n",
       " {'label': 'LABEL_0', 'score': 0.508101224899292},\n",
       " {'label': 'LABEL_0', 'score': 0.509382963180542},\n",
       " {'label': 'LABEL_0', 'score': 0.5125119686126709},\n",
       " {'label': 'LABEL_0', 'score': 0.5091631412506104},\n",
       " {'label': 'LABEL_0', 'score': 0.5101515650749207},\n",
       " {'label': 'LABEL_0', 'score': 0.5125454664230347},\n",
       " {'label': 'LABEL_0', 'score': 0.511354923248291},\n",
       " {'label': 'LABEL_0', 'score': 0.5068960785865784},\n",
       " {'label': 'LABEL_0', 'score': 0.505273163318634},\n",
       " {'label': 'LABEL_0', 'score': 0.5103191137313843},\n",
       " {'label': 'LABEL_0', 'score': 0.50819331407547},\n",
       " {'label': 'LABEL_0', 'score': 0.5067992210388184},\n",
       " {'label': 'LABEL_0', 'score': 0.5135302543640137},\n",
       " {'label': 'LABEL_0', 'score': 0.5106953382492065},\n",
       " {'label': 'LABEL_0', 'score': 0.5110113620758057},\n",
       " {'label': 'LABEL_0', 'score': 0.5160832405090332},\n",
       " {'label': 'LABEL_0', 'score': 0.5065376162528992},\n",
       " {'label': 'LABEL_0', 'score': 0.5120772123336792},\n",
       " {'label': 'LABEL_0', 'score': 0.5104683637619019},\n",
       " {'label': 'LABEL_0', 'score': 0.5100401043891907},\n",
       " {'label': 'LABEL_0', 'score': 0.5030310153961182},\n",
       " {'label': 'LABEL_0', 'score': 0.5122553110122681},\n",
       " {'label': 'LABEL_0', 'score': 0.5106715559959412},\n",
       " {'label': 'LABEL_0', 'score': 0.505805253982544},\n",
       " {'label': 'LABEL_1', 'score': 0.5032690167427063},\n",
       " {'label': 'LABEL_0', 'score': 0.510940670967102},\n",
       " {'label': 'LABEL_0', 'score': 0.508533775806427},\n",
       " {'label': 'LABEL_0', 'score': 0.5125189423561096},\n",
       " {'label': 'LABEL_0', 'score': 0.5054414868354797},\n",
       " {'label': 'LABEL_1', 'score': 0.5051772594451904},\n",
       " {'label': 'LABEL_0', 'score': 0.5104718208312988},\n",
       " {'label': 'LABEL_0', 'score': 0.5117558836936951},\n",
       " {'label': 'LABEL_0', 'score': 0.5120340585708618},\n",
       " {'label': 'LABEL_0', 'score': 0.5113930702209473},\n",
       " {'label': 'LABEL_0', 'score': 0.5083975791931152},\n",
       " {'label': 'LABEL_0', 'score': 0.5163136124610901},\n",
       " {'label': 'LABEL_0', 'score': 0.5052770376205444},\n",
       " {'label': 'LABEL_0', 'score': 0.5089253187179565},\n",
       " {'label': 'LABEL_0', 'score': 0.5131158828735352},\n",
       " {'label': 'LABEL_0', 'score': 0.5055204033851624},\n",
       " {'label': 'LABEL_0', 'score': 0.5085211992263794},\n",
       " {'label': 'LABEL_0', 'score': 0.5141687393188477},\n",
       " {'label': 'LABEL_0', 'score': 0.507663369178772},\n",
       " {'label': 'LABEL_0', 'score': 0.5067358613014221},\n",
       " {'label': 'LABEL_0', 'score': 0.5118791460990906},\n",
       " {'label': 'LABEL_0', 'score': 0.5116114616394043},\n",
       " {'label': 'LABEL_0', 'score': 0.5035727620124817},\n",
       " {'label': 'LABEL_0', 'score': 0.5108763575553894},\n",
       " {'label': 'LABEL_0', 'score': 0.5168978571891785},\n",
       " {'label': 'LABEL_0', 'score': 0.5079885721206665},\n",
       " {'label': 'LABEL_0', 'score': 0.5115148425102234},\n",
       " {'label': 'LABEL_0', 'score': 0.509525716304779},\n",
       " {'label': 'LABEL_0', 'score': 0.5098536610603333},\n",
       " {'label': 'LABEL_0', 'score': 0.501375138759613},\n",
       " {'label': 'LABEL_0', 'score': 0.5005908608436584},\n",
       " {'label': 'LABEL_0', 'score': 0.5061354637145996},\n",
       " {'label': 'LABEL_0', 'score': 0.5049083828926086},\n",
       " {'label': 'LABEL_0', 'score': 0.5114536285400391},\n",
       " {'label': 'LABEL_0', 'score': 0.507189929485321},\n",
       " {'label': 'LABEL_0', 'score': 0.5069175958633423},\n",
       " {'label': 'LABEL_0', 'score': 0.5101475715637207},\n",
       " {'label': 'LABEL_0', 'score': 0.5113773345947266},\n",
       " {'label': 'LABEL_0', 'score': 0.5079323053359985},\n",
       " {'label': 'LABEL_0', 'score': 0.5065163373947144},\n",
       " {'label': 'LABEL_0', 'score': 0.5093905925750732},\n",
       " {'label': 'LABEL_0', 'score': 0.5123573541641235},\n",
       " {'label': 'LABEL_0', 'score': 0.5063709020614624},\n",
       " {'label': 'LABEL_0', 'score': 0.5089058876037598},\n",
       " {'label': 'LABEL_0', 'score': 0.5055111646652222},\n",
       " {'label': 'LABEL_0', 'score': 0.5100417137145996},\n",
       " {'label': 'LABEL_0', 'score': 0.5114498734474182},\n",
       " {'label': 'LABEL_0', 'score': 0.5046667456626892},\n",
       " {'label': 'LABEL_0', 'score': 0.5083912014961243},\n",
       " {'label': 'LABEL_0', 'score': 0.5077601671218872},\n",
       " {'label': 'LABEL_0', 'score': 0.5140133500099182},\n",
       " {'label': 'LABEL_0', 'score': 0.5067606568336487},\n",
       " {'label': 'LABEL_0', 'score': 0.5082985758781433},\n",
       " {'label': 'LABEL_0', 'score': 0.5004666447639465},\n",
       " {'label': 'LABEL_0', 'score': 0.505352795124054},\n",
       " {'label': 'LABEL_0', 'score': 0.5065475702285767},\n",
       " {'label': 'LABEL_0', 'score': 0.5055091381072998},\n",
       " {'label': 'LABEL_0', 'score': 0.5114832520484924},\n",
       " {'label': 'LABEL_0', 'score': 0.5080248117446899},\n",
       " {'label': 'LABEL_0', 'score': 0.5027691721916199},\n",
       " {'label': 'LABEL_0', 'score': 0.5062897205352783},\n",
       " {'label': 'LABEL_0', 'score': 0.5106883645057678},\n",
       " {'label': 'LABEL_0', 'score': 0.5105833411216736},\n",
       " {'label': 'LABEL_0', 'score': 0.5015379786491394},\n",
       " {'label': 'LABEL_0', 'score': 0.5099815726280212},\n",
       " {'label': 'LABEL_0', 'score': 0.5050487518310547},\n",
       " {'label': 'LABEL_0', 'score': 0.5118311047554016},\n",
       " {'label': 'LABEL_0', 'score': 0.5043432116508484},\n",
       " {'label': 'LABEL_0', 'score': 0.5119652152061462},\n",
       " {'label': 'LABEL_0', 'score': 0.5106344223022461},\n",
       " {'label': 'LABEL_0', 'score': 0.5039841532707214},\n",
       " {'label': 'LABEL_0', 'score': 0.5124419331550598},\n",
       " {'label': 'LABEL_0', 'score': 0.512517511844635},\n",
       " {'label': 'LABEL_0', 'score': 0.5081089735031128},\n",
       " {'label': 'LABEL_0', 'score': 0.5115563869476318},\n",
       " {'label': 'LABEL_0', 'score': 0.5010888576507568},\n",
       " {'label': 'LABEL_0', 'score': 0.5085813403129578},\n",
       " {'label': 'LABEL_0', 'score': 0.5150975584983826},\n",
       " {'label': 'LABEL_0', 'score': 0.5000628232955933},\n",
       " {'label': 'LABEL_0', 'score': 0.5049682855606079},\n",
       " {'label': 'LABEL_0', 'score': 0.5097041726112366},\n",
       " {'label': 'LABEL_0', 'score': 0.5143566131591797},\n",
       " {'label': 'LABEL_0', 'score': 0.5070147514343262},\n",
       " {'label': 'LABEL_0', 'score': 0.5140728950500488},\n",
       " {'label': 'LABEL_0', 'score': 0.5040122270584106},\n",
       " {'label': 'LABEL_0', 'score': 0.5066162347793579},\n",
       " {'label': 'LABEL_0', 'score': 0.5095170140266418},\n",
       " {'label': 'LABEL_0', 'score': 0.5058467388153076},\n",
       " {'label': 'LABEL_0', 'score': 0.5081186294555664},\n",
       " {'label': 'LABEL_0', 'score': 0.509024441242218},\n",
       " {'label': 'LABEL_0', 'score': 0.5100886225700378},\n",
       " {'label': 'LABEL_0', 'score': 0.5092115998268127},\n",
       " {'label': 'LABEL_0', 'score': 0.512226402759552},\n",
       " {'label': 'LABEL_0', 'score': 0.5109328031539917},\n",
       " {'label': 'LABEL_0', 'score': 0.5099119544029236},\n",
       " {'label': 'LABEL_0', 'score': 0.5130184292793274},\n",
       " {'label': 'LABEL_0', 'score': 0.5087732076644897},\n",
       " {'label': 'LABEL_0', 'score': 0.5103222131729126},\n",
       " {'label': 'LABEL_0', 'score': 0.505744218826294},\n",
       " {'label': 'LABEL_0', 'score': 0.5028942823410034},\n",
       " {'label': 'LABEL_0', 'score': 0.5039471387863159},\n",
       " {'label': 'LABEL_0', 'score': 0.5038407444953918},\n",
       " {'label': 'LABEL_0', 'score': 0.5066468119621277},\n",
       " {'label': 'LABEL_0', 'score': 0.5009520053863525},\n",
       " {'label': 'LABEL_0', 'score': 0.5049694776535034},\n",
       " {'label': 'LABEL_0', 'score': 0.5110788941383362},\n",
       " {'label': 'LABEL_0', 'score': 0.5094914436340332},\n",
       " {'label': 'LABEL_0', 'score': 0.5070360898971558},\n",
       " {'label': 'LABEL_0', 'score': 0.5096606612205505},\n",
       " {'label': 'LABEL_0', 'score': 0.507707953453064},\n",
       " {'label': 'LABEL_0', 'score': 0.5125906467437744},\n",
       " {'label': 'LABEL_0', 'score': 0.5058662295341492},\n",
       " {'label': 'LABEL_0', 'score': 0.5086436867713928},\n",
       " {'label': 'LABEL_0', 'score': 0.5086798071861267},\n",
       " {'label': 'LABEL_0', 'score': 0.5117174386978149},\n",
       " {'label': 'LABEL_0', 'score': 0.5144486427307129},\n",
       " {'label': 'LABEL_0', 'score': 0.5097917318344116},\n",
       " {'label': 'LABEL_0', 'score': 0.5104279518127441},\n",
       " {'label': 'LABEL_0', 'score': 0.5093657970428467},\n",
       " {'label': 'LABEL_0', 'score': 0.5141164660453796},\n",
       " {'label': 'LABEL_0', 'score': 0.5065566301345825},\n",
       " {'label': 'LABEL_0', 'score': 0.5099690556526184},\n",
       " {'label': 'LABEL_0', 'score': 0.5105761289596558},\n",
       " {'label': 'LABEL_0', 'score': 0.5104942917823792},\n",
       " {'label': 'LABEL_0', 'score': 0.5068493485450745},\n",
       " {'label': 'LABEL_0', 'score': 0.512427568435669},\n",
       " {'label': 'LABEL_0', 'score': 0.5109639167785645},\n",
       " {'label': 'LABEL_0', 'score': 0.5133079290390015},\n",
       " {'label': 'LABEL_0', 'score': 0.5091025233268738},\n",
       " {'label': 'LABEL_0', 'score': 0.5094112157821655},\n",
       " {'label': 'LABEL_0', 'score': 0.502735435962677},\n",
       " {'label': 'LABEL_0', 'score': 0.5130325555801392},\n",
       " {'label': 'LABEL_0', 'score': 0.5048331618309021},\n",
       " {'label': 'LABEL_0', 'score': 0.5068220496177673},\n",
       " {'label': 'LABEL_0', 'score': 0.5078116655349731},\n",
       " {'label': 'LABEL_0', 'score': 0.5044470429420471},\n",
       " {'label': 'LABEL_0', 'score': 0.5138747692108154},\n",
       " {'label': 'LABEL_0', 'score': 0.5090346932411194},\n",
       " {'label': 'LABEL_1', 'score': 0.5003337264060974},\n",
       " {'label': 'LABEL_0', 'score': 0.5087273716926575},\n",
       " {'label': 'LABEL_0', 'score': 0.5118780136108398},\n",
       " {'label': 'LABEL_0', 'score': 0.5100014805793762},\n",
       " {'label': 'LABEL_0', 'score': 0.5094614028930664},\n",
       " {'label': 'LABEL_0', 'score': 0.5053050518035889},\n",
       " {'label': 'LABEL_0', 'score': 0.50871342420578},\n",
       " {'label': 'LABEL_0', 'score': 0.511833667755127},\n",
       " {'label': 'LABEL_0', 'score': 0.5005401372909546},\n",
       " {'label': 'LABEL_0', 'score': 0.509647011756897},\n",
       " {'label': 'LABEL_0', 'score': 0.5083276033401489},\n",
       " {'label': 'LABEL_0', 'score': 0.5118849277496338},\n",
       " {'label': 'LABEL_0', 'score': 0.5087758898735046},\n",
       " {'label': 'LABEL_0', 'score': 0.5109707117080688},\n",
       " {'label': 'LABEL_0', 'score': 0.5072571635246277},\n",
       " {'label': 'LABEL_0', 'score': 0.5104444026947021},\n",
       " {'label': 'LABEL_0', 'score': 0.5133723616600037},\n",
       " {'label': 'LABEL_0', 'score': 0.5126702785491943},\n",
       " {'label': 'LABEL_0', 'score': 0.5099158883094788},\n",
       " {'label': 'LABEL_0', 'score': 0.5153292417526245},\n",
       " {'label': 'LABEL_0', 'score': 0.5065790414810181},\n",
       " {'label': 'LABEL_0', 'score': 0.5090758204460144},\n",
       " {'label': 'LABEL_0', 'score': 0.509524941444397},\n",
       " {'label': 'LABEL_0', 'score': 0.5068048238754272},\n",
       " {'label': 'LABEL_0', 'score': 0.5035885572433472},\n",
       " {'label': 'LABEL_0', 'score': 0.5043849349021912},\n",
       " {'label': 'LABEL_0', 'score': 0.5114468932151794},\n",
       " {'label': 'LABEL_0', 'score': 0.5049316883087158},\n",
       " {'label': 'LABEL_0', 'score': 0.5082204341888428},\n",
       " {'label': 'LABEL_0', 'score': 0.5010090470314026},\n",
       " {'label': 'LABEL_0', 'score': 0.5108070373535156},\n",
       " {'label': 'LABEL_0', 'score': 0.5056790113449097},\n",
       " {'label': 'LABEL_0', 'score': 0.5120974779129028},\n",
       " {'label': 'LABEL_1', 'score': 0.5046308040618896},\n",
       " {'label': 'LABEL_0', 'score': 0.513460636138916},\n",
       " {'label': 'LABEL_0', 'score': 0.51401686668396},\n",
       " {'label': 'LABEL_0', 'score': 0.5083755850791931},\n",
       " {'label': 'LABEL_0', 'score': 0.5150671601295471},\n",
       " {'label': 'LABEL_0', 'score': 0.5123316645622253},\n",
       " {'label': 'LABEL_0', 'score': 0.5115479826927185},\n",
       " {'label': 'LABEL_0', 'score': 0.5139480233192444},\n",
       " {'label': 'LABEL_0', 'score': 0.5129938721656799},\n",
       " {'label': 'LABEL_0', 'score': 0.5108495354652405},\n",
       " {'label': 'LABEL_0', 'score': 0.5121576189994812},\n",
       " {'label': 'LABEL_0', 'score': 0.5090683102607727},\n",
       " {'label': 'LABEL_0', 'score': 0.5114142298698425},\n",
       " {'label': 'LABEL_0', 'score': 0.5131150484085083},\n",
       " {'label': 'LABEL_0', 'score': 0.5099226832389832},\n",
       " {'label': 'LABEL_0', 'score': 0.5141080021858215},\n",
       " {'label': 'LABEL_0', 'score': 0.5101318359375},\n",
       " {'label': 'LABEL_0', 'score': 0.5130529403686523},\n",
       " {'label': 'LABEL_0', 'score': 0.5078986287117004},\n",
       " {'label': 'LABEL_0', 'score': 0.5126945376396179},\n",
       " {'label': 'LABEL_0', 'score': 0.5111408233642578},\n",
       " {'label': 'LABEL_0', 'score': 0.5123972296714783},\n",
       " {'label': 'LABEL_0', 'score': 0.5135484337806702},\n",
       " {'label': 'LABEL_0', 'score': 0.5070690512657166},\n",
       " {'label': 'LABEL_0', 'score': 0.5120006203651428},\n",
       " {'label': 'LABEL_0', 'score': 0.5092071294784546},\n",
       " {'label': 'LABEL_0', 'score': 0.5100821852684021},\n",
       " {'label': 'LABEL_0', 'score': 0.5093759298324585},\n",
       " {'label': 'LABEL_0', 'score': 0.5048930048942566},\n",
       " {'label': 'LABEL_0', 'score': 0.5115612149238586},\n",
       " {'label': 'LABEL_0', 'score': 0.5032595992088318},\n",
       " {'label': 'LABEL_0', 'score': 0.5117811560630798},\n",
       " {'label': 'LABEL_0', 'score': 0.5105782151222229},\n",
       " {'label': 'LABEL_0', 'score': 0.5152496099472046},\n",
       " {'label': 'LABEL_0', 'score': 0.5110788345336914},\n",
       " {'label': 'LABEL_0', 'score': 0.5157409310340881},\n",
       " {'label': 'LABEL_0', 'score': 0.5066226720809937},\n",
       " {'label': 'LABEL_0', 'score': 0.5098428726196289},\n",
       " {'label': 'LABEL_0', 'score': 0.5090144276618958},\n",
       " {'label': 'LABEL_0', 'score': 0.5057976245880127},\n",
       " {'label': 'LABEL_0', 'score': 0.5092623233795166},\n",
       " {'label': 'LABEL_0', 'score': 0.5075724124908447},\n",
       " {'label': 'LABEL_0', 'score': 0.5114899277687073},\n",
       " {'label': 'LABEL_0', 'score': 0.5076909065246582},\n",
       " {'label': 'LABEL_0', 'score': 0.5100780129432678},\n",
       " {'label': 'LABEL_0', 'score': 0.5095492601394653},\n",
       " {'label': 'LABEL_0', 'score': 0.5039897561073303},\n",
       " {'label': 'LABEL_0', 'score': 0.5111533403396606},\n",
       " {'label': 'LABEL_0', 'score': 0.5113763809204102},\n",
       " {'label': 'LABEL_0', 'score': 0.5079289078712463},\n",
       " {'label': 'LABEL_0', 'score': 0.5095263719558716},\n",
       " {'label': 'LABEL_0', 'score': 0.5042808055877686},\n",
       " {'label': 'LABEL_0', 'score': 0.5120068788528442},\n",
       " {'label': 'LABEL_0', 'score': 0.5070526599884033},\n",
       " {'label': 'LABEL_0', 'score': 0.5076850056648254},\n",
       " {'label': 'LABEL_0', 'score': 0.5147096514701843},\n",
       " {'label': 'LABEL_0', 'score': 0.5046136975288391},\n",
       " {'label': 'LABEL_0', 'score': 0.5054166913032532},\n",
       " {'label': 'LABEL_0', 'score': 0.504631519317627},\n",
       " {'label': 'LABEL_0', 'score': 0.5112525224685669},\n",
       " {'label': 'LABEL_0', 'score': 0.5036628842353821},\n",
       " {'label': 'LABEL_0', 'score': 0.5107004642486572},\n",
       " {'label': 'LABEL_0', 'score': 0.5113184452056885},\n",
       " {'label': 'LABEL_0', 'score': 0.5161610841751099},\n",
       " {'label': 'LABEL_0', 'score': 0.5079443454742432},\n",
       " {'label': 'LABEL_0', 'score': 0.5108547806739807},\n",
       " {'label': 'LABEL_0', 'score': 0.512653648853302},\n",
       " {'label': 'LABEL_0', 'score': 0.5083053708076477},\n",
       " {'label': 'LABEL_0', 'score': 0.5092625617980957},\n",
       " {'label': 'LABEL_0', 'score': 0.5108550786972046},\n",
       " {'label': 'LABEL_0', 'score': 0.5101104974746704},\n",
       " {'label': 'LABEL_0', 'score': 0.5110347270965576},\n",
       " {'label': 'LABEL_0', 'score': 0.5056371688842773},\n",
       " {'label': 'LABEL_0', 'score': 0.5049710273742676},\n",
       " {'label': 'LABEL_0', 'score': 0.5046418309211731},\n",
       " {'label': 'LABEL_0', 'score': 0.5056784152984619},\n",
       " {'label': 'LABEL_0', 'score': 0.5062323212623596},\n",
       " {'label': 'LABEL_1', 'score': 0.5000766515731812},\n",
       " {'label': 'LABEL_0', 'score': 0.5085397958755493},\n",
       " {'label': 'LABEL_0', 'score': 0.5034326314926147},\n",
       " {'label': 'LABEL_0', 'score': 0.5101484060287476},\n",
       " {'label': 'LABEL_0', 'score': 0.5123632550239563},\n",
       " {'label': 'LABEL_0', 'score': 0.5076196789741516},\n",
       " {'label': 'LABEL_0', 'score': 0.5126795172691345},\n",
       " {'label': 'LABEL_0', 'score': 0.51228266954422},\n",
       " {'label': 'LABEL_0', 'score': 0.5070171356201172},\n",
       " {'label': 'LABEL_0', 'score': 0.5081579685211182},\n",
       " {'label': 'LABEL_0', 'score': 0.5043863654136658},\n",
       " {'label': 'LABEL_0', 'score': 0.5110814571380615},\n",
       " {'label': 'LABEL_0', 'score': 0.5089464783668518},\n",
       " {'label': 'LABEL_0', 'score': 0.5150651335716248},\n",
       " {'label': 'LABEL_0', 'score': 0.5109544992446899},\n",
       " {'label': 'LABEL_0', 'score': 0.510611891746521},\n",
       " {'label': 'LABEL_0', 'score': 0.5066219568252563},\n",
       " {'label': 'LABEL_0', 'score': 0.5137856602668762},\n",
       " {'label': 'LABEL_0', 'score': 0.5051001906394958},\n",
       " {'label': 'LABEL_0', 'score': 0.5087620615959167},\n",
       " {'label': 'LABEL_0', 'score': 0.5101741552352905},\n",
       " {'label': 'LABEL_0', 'score': 0.5074647068977356},\n",
       " {'label': 'LABEL_0', 'score': 0.5102148652076721},\n",
       " {'label': 'LABEL_1', 'score': 0.5002595782279968},\n",
       " {'label': 'LABEL_0', 'score': 0.5154444575309753},\n",
       " {'label': 'LABEL_0', 'score': 0.5119361877441406},\n",
       " {'label': 'LABEL_0', 'score': 0.5085136294364929},\n",
       " {'label': 'LABEL_0', 'score': 0.5134139060974121},\n",
       " {'label': 'LABEL_0', 'score': 0.5089856386184692},\n",
       " {'label': 'LABEL_0', 'score': 0.5091673731803894},\n",
       " {'label': 'LABEL_0', 'score': 0.5148482918739319},\n",
       " {'label': 'LABEL_0', 'score': 0.5146680474281311},\n",
       " {'label': 'LABEL_0', 'score': 0.5134890079498291},\n",
       " {'label': 'LABEL_0', 'score': 0.5021426677703857},\n",
       " {'label': 'LABEL_0', 'score': 0.5112731456756592},\n",
       " {'label': 'LABEL_0', 'score': 0.5094836354255676},\n",
       " {'label': 'LABEL_0', 'score': 0.5101606249809265},\n",
       " {'label': 'LABEL_0', 'score': 0.5043960213661194},\n",
       " {'label': 'LABEL_0', 'score': 0.5138813257217407},\n",
       " {'label': 'LABEL_0', 'score': 0.5124580264091492},\n",
       " {'label': 'LABEL_0', 'score': 0.513727068901062},\n",
       " {'label': 'LABEL_0', 'score': 0.5116021037101746},\n",
       " {'label': 'LABEL_0', 'score': 0.5124988555908203},\n",
       " {'label': 'LABEL_0', 'score': 0.5056055188179016},\n",
       " {'label': 'LABEL_0', 'score': 0.5104479789733887},\n",
       " {'label': 'LABEL_1', 'score': 0.50121009349823},\n",
       " {'label': 'LABEL_0', 'score': 0.5108957886695862},\n",
       " {'label': 'LABEL_0', 'score': 0.5036303400993347},\n",
       " {'label': 'LABEL_0', 'score': 0.5086548328399658},\n",
       " {'label': 'LABEL_0', 'score': 0.5014357566833496},\n",
       " {'label': 'LABEL_0', 'score': 0.5112577676773071},\n",
       " {'label': 'LABEL_0', 'score': 0.5095641613006592},\n",
       " {'label': 'LABEL_0', 'score': 0.5114334225654602},\n",
       " {'label': 'LABEL_0', 'score': 0.5038726925849915},\n",
       " {'label': 'LABEL_0', 'score': 0.506599485874176},\n",
       " {'label': 'LABEL_0', 'score': 0.5107652544975281},\n",
       " {'label': 'LABEL_0', 'score': 0.5092103481292725},\n",
       " {'label': 'LABEL_0', 'score': 0.5062651038169861},\n",
       " {'label': 'LABEL_0', 'score': 0.5148069262504578},\n",
       " {'label': 'LABEL_0', 'score': 0.5024257302284241},\n",
       " {'label': 'LABEL_0', 'score': 0.5091658234596252},\n",
       " {'label': 'LABEL_0', 'score': 0.5012437105178833},\n",
       " {'label': 'LABEL_0', 'score': 0.5090962052345276},\n",
       " {'label': 'LABEL_0', 'score': 0.5089311003684998},\n",
       " {'label': 'LABEL_0', 'score': 0.5085134506225586},\n",
       " {'label': 'LABEL_0', 'score': 0.5077334642410278},\n",
       " {'label': 'LABEL_0', 'score': 0.5079600214958191},\n",
       " {'label': 'LABEL_0', 'score': 0.5138830542564392},\n",
       " {'label': 'LABEL_0', 'score': 0.5081537365913391},\n",
       " {'label': 'LABEL_0', 'score': 0.5086302161216736},\n",
       " {'label': 'LABEL_0', 'score': 0.5044910311698914},\n",
       " {'label': 'LABEL_0', 'score': 0.5080735087394714},\n",
       " {'label': 'LABEL_0', 'score': 0.5093048810958862},\n",
       " {'label': 'LABEL_0', 'score': 0.5127667188644409},\n",
       " {'label': 'LABEL_0', 'score': 0.5152842402458191},\n",
       " {'label': 'LABEL_0', 'score': 0.5048907995223999},\n",
       " {'label': 'LABEL_0', 'score': 0.5022411346435547},\n",
       " {'label': 'LABEL_0', 'score': 0.5010766983032227},\n",
       " {'label': 'LABEL_0', 'score': 0.5103703737258911},\n",
       " {'label': 'LABEL_0', 'score': 0.5092766880989075},\n",
       " {'label': 'LABEL_0', 'score': 0.5131467580795288},\n",
       " {'label': 'LABEL_0', 'score': 0.5108978152275085},\n",
       " {'label': 'LABEL_0', 'score': 0.5147809386253357},\n",
       " {'label': 'LABEL_0', 'score': 0.5093210935592651},\n",
       " {'label': 'LABEL_0', 'score': 0.5107587575912476},\n",
       " {'label': 'LABEL_0', 'score': 0.5057650208473206},\n",
       " {'label': 'LABEL_0', 'score': 0.5093015432357788},\n",
       " {'label': 'LABEL_0', 'score': 0.5103029012680054},\n",
       " {'label': 'LABEL_0', 'score': 0.5099655389785767},\n",
       " {'label': 'LABEL_0', 'score': 0.508944034576416},\n",
       " {'label': 'LABEL_0', 'score': 0.5133069157600403},\n",
       " {'label': 'LABEL_0', 'score': 0.5000196695327759},\n",
       " {'label': 'LABEL_0', 'score': 0.5138109922409058},\n",
       " {'label': 'LABEL_0', 'score': 0.5117649435997009},\n",
       " {'label': 'LABEL_0', 'score': 0.5091496109962463},\n",
       " {'label': 'LABEL_0', 'score': 0.5064064860343933},\n",
       " {'label': 'LABEL_0', 'score': 0.5107408165931702},\n",
       " {'label': 'LABEL_0', 'score': 0.509675920009613},\n",
       " {'label': 'LABEL_0', 'score': 0.5103598833084106},\n",
       " {'label': 'LABEL_0', 'score': 0.5085541009902954},\n",
       " {'label': 'LABEL_0', 'score': 0.511811375617981},\n",
       " {'label': 'LABEL_0', 'score': 0.506317675113678},\n",
       " {'label': 'LABEL_0', 'score': 0.5106016397476196},\n",
       " {'label': 'LABEL_0', 'score': 0.5094702839851379},\n",
       " {'label': 'LABEL_0', 'score': 0.5088054537773132},\n",
       " {'label': 'LABEL_0', 'score': 0.5030349493026733},\n",
       " {'label': 'LABEL_0', 'score': 0.5055078268051147},\n",
       " {'label': 'LABEL_0', 'score': 0.5098408460617065},\n",
       " {'label': 'LABEL_0', 'score': 0.5108568072319031},\n",
       " {'label': 'LABEL_0', 'score': 0.5135799646377563},\n",
       " {'label': 'LABEL_0', 'score': 0.5098666548728943},\n",
       " {'label': 'LABEL_0', 'score': 0.510071337223053},\n",
       " {'label': 'LABEL_0', 'score': 0.5092872381210327},\n",
       " {'label': 'LABEL_0', 'score': 0.5083134174346924},\n",
       " {'label': 'LABEL_1', 'score': 0.5025909543037415},\n",
       " {'label': 'LABEL_1', 'score': 0.500810980796814},\n",
       " {'label': 'LABEL_0', 'score': 0.514137327671051},\n",
       " {'label': 'LABEL_0', 'score': 0.5062375068664551},\n",
       " {'label': 'LABEL_0', 'score': 0.5079866647720337},\n",
       " {'label': 'LABEL_0', 'score': 0.5106551647186279},\n",
       " {'label': 'LABEL_0', 'score': 0.5095454454421997},\n",
       " {'label': 'LABEL_1', 'score': 0.5008540153503418},\n",
       " {'label': 'LABEL_0', 'score': 0.507716178894043},\n",
       " {'label': 'LABEL_0', 'score': 0.5108800530433655},\n",
       " {'label': 'LABEL_0', 'score': 0.5087308287620544},\n",
       " {'label': 'LABEL_0', 'score': 0.5024359226226807},\n",
       " {'label': 'LABEL_0', 'score': 0.511869490146637},\n",
       " {'label': 'LABEL_1', 'score': 0.5035548210144043},\n",
       " {'label': 'LABEL_0', 'score': 0.506048858165741},\n",
       " {'label': 'LABEL_0', 'score': 0.501615047454834},\n",
       " {'label': 'LABEL_0', 'score': 0.5095812082290649},\n",
       " {'label': 'LABEL_0', 'score': 0.5091879963874817},\n",
       " {'label': 'LABEL_0', 'score': 0.5107347369194031},\n",
       " {'label': 'LABEL_0', 'score': 0.508615255355835},\n",
       " {'label': 'LABEL_0', 'score': 0.5050742030143738},\n",
       " {'label': 'LABEL_0', 'score': 0.5010901093482971},\n",
       " {'label': 'LABEL_0', 'score': 0.5128313302993774},\n",
       " {'label': 'LABEL_0', 'score': 0.5072683691978455},\n",
       " {'label': 'LABEL_0', 'score': 0.5035200119018555},\n",
       " {'label': 'LABEL_0', 'score': 0.5151466727256775},\n",
       " {'label': 'LABEL_0', 'score': 0.5130800604820251},\n",
       " {'label': 'LABEL_0', 'score': 0.5130638480186462},\n",
       " {'label': 'LABEL_0', 'score': 0.5071843266487122},\n",
       " {'label': 'LABEL_0', 'score': 0.503319263458252},\n",
       " {'label': 'LABEL_0', 'score': 0.507448673248291},\n",
       " {'label': 'LABEL_0', 'score': 0.5037404298782349},\n",
       " {'label': 'LABEL_0', 'score': 0.5084280967712402},\n",
       " {'label': 'LABEL_0', 'score': 0.5064231157302856},\n",
       " {'label': 'LABEL_0', 'score': 0.5082302689552307},\n",
       " {'label': 'LABEL_0', 'score': 0.510896623134613},\n",
       " {'label': 'LABEL_0', 'score': 0.5036360621452332},\n",
       " {'label': 'LABEL_0', 'score': 0.5120605826377869},\n",
       " {'label': 'LABEL_0', 'score': 0.5138428807258606},\n",
       " {'label': 'LABEL_0', 'score': 0.5127933025360107},\n",
       " {'label': 'LABEL_0', 'score': 0.5093405246734619},\n",
       " {'label': 'LABEL_1', 'score': 0.5011560320854187},\n",
       " {'label': 'LABEL_0', 'score': 0.5021852850914001},\n",
       " {'label': 'LABEL_0', 'score': 0.5083600878715515},\n",
       " {'label': 'LABEL_0', 'score': 0.5154987573623657},\n",
       " {'label': 'LABEL_0', 'score': 0.509380042552948},\n",
       " {'label': 'LABEL_0', 'score': 0.5030566453933716},\n",
       " {'label': 'LABEL_0', 'score': 0.5114713311195374},\n",
       " {'label': 'LABEL_1', 'score': 0.5007238388061523},\n",
       " {'label': 'LABEL_0', 'score': 0.5060370564460754},\n",
       " {'label': 'LABEL_0', 'score': 0.5004516839981079},\n",
       " {'label': 'LABEL_0', 'score': 0.5118388533592224},\n",
       " {'label': 'LABEL_0', 'score': 0.5054575204849243},\n",
       " {'label': 'LABEL_0', 'score': 0.5050542950630188},\n",
       " {'label': 'LABEL_0', 'score': 0.5093297958374023},\n",
       " {'label': 'LABEL_0', 'score': 0.5126409530639648},\n",
       " {'label': 'LABEL_0', 'score': 0.5051068067550659},\n",
       " {'label': 'LABEL_0', 'score': 0.5066416263580322},\n",
       " {'label': 'LABEL_0', 'score': 0.5127342939376831},\n",
       " {'label': 'LABEL_0', 'score': 0.516677975654602},\n",
       " {'label': 'LABEL_0', 'score': 0.511383593082428},\n",
       " {'label': 'LABEL_0', 'score': 0.5072439908981323},\n",
       " {'label': 'LABEL_0', 'score': 0.5103709697723389},\n",
       " {'label': 'LABEL_0', 'score': 0.5114186406135559},\n",
       " {'label': 'LABEL_0', 'score': 0.5097283720970154},\n",
       " {'label': 'LABEL_0', 'score': 0.5151395797729492},\n",
       " {'label': 'LABEL_0', 'score': 0.5063998103141785},\n",
       " {'label': 'LABEL_1', 'score': 0.504629909992218},\n",
       " {'label': 'LABEL_0', 'score': 0.5140618085861206},\n",
       " {'label': 'LABEL_0', 'score': 0.5119704604148865},\n",
       " {'label': 'LABEL_0', 'score': 0.5049430727958679},\n",
       " {'label': 'LABEL_0', 'score': 0.5042337775230408},\n",
       " {'label': 'LABEL_1', 'score': 0.5006484985351562},\n",
       " {'label': 'LABEL_1', 'score': 0.5011914372444153},\n",
       " {'label': 'LABEL_0', 'score': 0.5152034163475037},\n",
       " {'label': 'LABEL_0', 'score': 0.5145349502563477},\n",
       " {'label': 'LABEL_0', 'score': 0.5138515830039978},\n",
       " {'label': 'LABEL_0', 'score': 0.5139745473861694},\n",
       " {'label': 'LABEL_0', 'score': 0.5116061568260193},\n",
       " {'label': 'LABEL_0', 'score': 0.5090305209159851},\n",
       " {'label': 'LABEL_0', 'score': 0.5061654448509216},\n",
       " {'label': 'LABEL_0', 'score': 0.5095824599266052},\n",
       " {'label': 'LABEL_0', 'score': 0.5066432952880859},\n",
       " {'label': 'LABEL_0', 'score': 0.5092258453369141},\n",
       " {'label': 'LABEL_0', 'score': 0.5084452629089355},\n",
       " {'label': 'LABEL_1', 'score': 0.5014524459838867},\n",
       " {'label': 'LABEL_0', 'score': 0.5145043730735779},\n",
       " {'label': 'LABEL_0', 'score': 0.5120856761932373},\n",
       " {'label': 'LABEL_0', 'score': 0.5109307169914246},\n",
       " {'label': 'LABEL_0', 'score': 0.5095303654670715},\n",
       " {'label': 'LABEL_0', 'score': 0.50688236951828},\n",
       " {'label': 'LABEL_0', 'score': 0.5150477290153503},\n",
       " {'label': 'LABEL_0', 'score': 0.5079358816146851},\n",
       " {'label': 'LABEL_0', 'score': 0.510956346988678},\n",
       " {'label': 'LABEL_0', 'score': 0.506525456905365},\n",
       " {'label': 'LABEL_0', 'score': 0.5119449496269226},\n",
       " {'label': 'LABEL_0', 'score': 0.51508629322052},\n",
       " {'label': 'LABEL_0', 'score': 0.5113738179206848},\n",
       " {'label': 'LABEL_0', 'score': 0.509101390838623},\n",
       " {'label': 'LABEL_0', 'score': 0.502726674079895},\n",
       " {'label': 'LABEL_0', 'score': 0.5027923583984375},\n",
       " {'label': 'LABEL_0', 'score': 0.5108935832977295},\n",
       " {'label': 'LABEL_0', 'score': 0.5148175954818726},\n",
       " {'label': 'LABEL_0', 'score': 0.5140565633773804},\n",
       " {'label': 'LABEL_0', 'score': 0.51014643907547},\n",
       " {'label': 'LABEL_0', 'score': 0.5132465958595276},\n",
       " {'label': 'LABEL_0', 'score': 0.5101792812347412},\n",
       " {'label': 'LABEL_0', 'score': 0.5068047046661377},\n",
       " {'label': 'LABEL_0', 'score': 0.5107721090316772},\n",
       " {'label': 'LABEL_1', 'score': 0.5003980994224548},\n",
       " {'label': 'LABEL_0', 'score': 0.5100961923599243},\n",
       " {'label': 'LABEL_0', 'score': 0.5093791484832764},\n",
       " {'label': 'LABEL_0', 'score': 0.5121188759803772},\n",
       " {'label': 'LABEL_0', 'score': 0.5132371187210083},\n",
       " {'label': 'LABEL_0', 'score': 0.5087307691574097},\n",
       " {'label': 'LABEL_0', 'score': 0.5097310543060303},\n",
       " {'label': 'LABEL_0', 'score': 0.5149418115615845},\n",
       " {'label': 'LABEL_0', 'score': 0.5085369944572449},\n",
       " {'label': 'LABEL_0', 'score': 0.5107806324958801},\n",
       " {'label': 'LABEL_0', 'score': 0.5082709193229675},\n",
       " {'label': 'LABEL_0', 'score': 0.5035908818244934},\n",
       " {'label': 'LABEL_0', 'score': 0.5127534866333008},\n",
       " {'label': 'LABEL_0', 'score': 0.5119205713272095},\n",
       " {'label': 'LABEL_0', 'score': 0.5066076517105103},\n",
       " {'label': 'LABEL_0', 'score': 0.5080309510231018},\n",
       " {'label': 'LABEL_0', 'score': 0.5090801119804382},\n",
       " {'label': 'LABEL_0', 'score': 0.5164708495140076},\n",
       " {'label': 'LABEL_0', 'score': 0.507139265537262},\n",
       " {'label': 'LABEL_0', 'score': 0.5076118111610413},\n",
       " {'label': 'LABEL_0', 'score': 0.5116943717002869},\n",
       " {'label': 'LABEL_0', 'score': 0.5110336542129517},\n",
       " {'label': 'LABEL_0', 'score': 0.5056922435760498},\n",
       " {'label': 'LABEL_0', 'score': 0.5169669985771179},\n",
       " {'label': 'LABEL_0', 'score': 0.5108534693717957},\n",
       " {'label': 'LABEL_0', 'score': 0.5077333450317383},\n",
       " {'label': 'LABEL_0', 'score': 0.5079071521759033},\n",
       " {'label': 'LABEL_0', 'score': 0.5075703263282776},\n",
       " {'label': 'LABEL_0', 'score': 0.5087990164756775},\n",
       " {'label': 'LABEL_0', 'score': 0.5126588344573975},\n",
       " {'label': 'LABEL_0', 'score': 0.5110466480255127},\n",
       " {'label': 'LABEL_0', 'score': 0.5076373219490051},\n",
       " {'label': 'LABEL_0', 'score': 0.5124215483665466},\n",
       " {'label': 'LABEL_0', 'score': 0.510713517665863},\n",
       " {'label': 'LABEL_0', 'score': 0.509495735168457},\n",
       " {'label': 'LABEL_0', 'score': 0.5143309235572815},\n",
       " {'label': 'LABEL_0', 'score': 0.5159955024719238},\n",
       " {'label': 'LABEL_0', 'score': 0.512839674949646},\n",
       " {'label': 'LABEL_0', 'score': 0.5103582739830017},\n",
       " {'label': 'LABEL_1', 'score': 0.5024537444114685},\n",
       " {'label': 'LABEL_0', 'score': 0.5136625170707703},\n",
       " {'label': 'LABEL_0', 'score': 0.5076946020126343},\n",
       " {'label': 'LABEL_0', 'score': 0.5105329155921936},\n",
       " {'label': 'LABEL_0', 'score': 0.5176436305046082},\n",
       " {'label': 'LABEL_0', 'score': 0.5073769092559814},\n",
       " {'label': 'LABEL_0', 'score': 0.5093988180160522},\n",
       " {'label': 'LABEL_0', 'score': 0.5063563585281372},\n",
       " {'label': 'LABEL_0', 'score': 0.5117036700248718},\n",
       " {'label': 'LABEL_0', 'score': 0.5131186842918396},\n",
       " {'label': 'LABEL_0', 'score': 0.5142194032669067},\n",
       " {'label': 'LABEL_0', 'score': 0.5014733672142029},\n",
       " {'label': 'LABEL_1', 'score': 0.5090455412864685},\n",
       " {'label': 'LABEL_0', 'score': 0.5092544555664062},\n",
       " {'label': 'LABEL_0', 'score': 0.5082369446754456},\n",
       " {'label': 'LABEL_0', 'score': 0.5079193115234375},\n",
       " {'label': 'LABEL_0', 'score': 0.5121583342552185},\n",
       " {'label': 'LABEL_0', 'score': 0.5080308318138123},\n",
       " {'label': 'LABEL_0', 'score': 0.5051007270812988},\n",
       " {'label': 'LABEL_0', 'score': 0.5119478702545166},\n",
       " {'label': 'LABEL_0', 'score': 0.5103795528411865},\n",
       " {'label': 'LABEL_0', 'score': 0.5088121891021729},\n",
       " {'label': 'LABEL_0', 'score': 0.5114670395851135},\n",
       " {'label': 'LABEL_0', 'score': 0.5098531246185303},\n",
       " {'label': 'LABEL_0', 'score': 0.5119637250900269},\n",
       " {'label': 'LABEL_0', 'score': 0.5150695443153381},\n",
       " {'label': 'LABEL_0', 'score': 0.5011350512504578},\n",
       " {'label': 'LABEL_0', 'score': 0.5099169015884399},\n",
       " {'label': 'LABEL_0', 'score': 0.5060872435569763},\n",
       " {'label': 'LABEL_0', 'score': 0.5103482007980347},\n",
       " {'label': 'LABEL_0', 'score': 0.5105329155921936},\n",
       " {'label': 'LABEL_0', 'score': 0.5093926787376404},\n",
       " {'label': 'LABEL_0', 'score': 0.5091804265975952},\n",
       " {'label': 'LABEL_0', 'score': 0.5047476887702942},\n",
       " {'label': 'LABEL_0', 'score': 0.5090041756629944},\n",
       " {'label': 'LABEL_0', 'score': 0.5107100605964661},\n",
       " {'label': 'LABEL_1', 'score': 0.5027505159378052},\n",
       " {'label': 'LABEL_0', 'score': 0.5099546909332275},\n",
       " {'label': 'LABEL_1', 'score': 0.5011518597602844},\n",
       " {'label': 'LABEL_0', 'score': 0.5096418857574463},\n",
       " {'label': 'LABEL_0', 'score': 0.503202497959137},\n",
       " {'label': 'LABEL_0', 'score': 0.5109540820121765},\n",
       " {'label': 'LABEL_0', 'score': 0.5124797224998474},\n",
       " {'label': 'LABEL_0', 'score': 0.5129392743110657},\n",
       " {'label': 'LABEL_1', 'score': 0.5003374218940735},\n",
       " {'label': 'LABEL_1', 'score': 0.5078366994857788},\n",
       " {'label': 'LABEL_0', 'score': 0.5070470571517944},\n",
       " {'label': 'LABEL_0', 'score': 0.5085718035697937},\n",
       " {'label': 'LABEL_0', 'score': 0.5126544237136841},\n",
       " {'label': 'LABEL_0', 'score': 0.5107155442237854},\n",
       " {'label': 'LABEL_0', 'score': 0.5112255811691284},\n",
       " {'label': 'LABEL_1', 'score': 0.5010051727294922},\n",
       " {'label': 'LABEL_0', 'score': 0.5072251558303833},\n",
       " {'label': 'LABEL_0', 'score': 0.5099188089370728},\n",
       " {'label': 'LABEL_0', 'score': 0.5059275031089783},\n",
       " {'label': 'LABEL_1', 'score': 0.5125452876091003},\n",
       " {'label': 'LABEL_0', 'score': 0.5064926147460938},\n",
       " {'label': 'LABEL_0', 'score': 0.5051419138908386},\n",
       " {'label': 'LABEL_0', 'score': 0.5113425254821777},\n",
       " {'label': 'LABEL_0', 'score': 0.512301504611969},\n",
       " {'label': 'LABEL_0', 'score': 0.5116937160491943},\n",
       " {'label': 'LABEL_0', 'score': 0.5056977272033691},\n",
       " {'label': 'LABEL_0', 'score': 0.5150708556175232},\n",
       " {'label': 'LABEL_1', 'score': 0.5007883310317993},\n",
       " {'label': 'LABEL_0', 'score': 0.5121132731437683},\n",
       " {'label': 'LABEL_0', 'score': 0.5099912881851196},\n",
       " {'label': 'LABEL_0', 'score': 0.5070508718490601},\n",
       " {'label': 'LABEL_0', 'score': 0.5089687705039978},\n",
       " {'label': 'LABEL_0', 'score': 0.5128204226493835},\n",
       " {'label': 'LABEL_0', 'score': 0.5084425210952759},\n",
       " {'label': 'LABEL_0', 'score': 0.5134906768798828},\n",
       " {'label': 'LABEL_0', 'score': 0.5060296654701233},\n",
       " {'label': 'LABEL_0', 'score': 0.5070257186889648},\n",
       " {'label': 'LABEL_0', 'score': 0.5142198204994202},\n",
       " {'label': 'LABEL_0', 'score': 0.5064919590950012},\n",
       " {'label': 'LABEL_0', 'score': 0.5101215839385986},\n",
       " {'label': 'LABEL_0', 'score': 0.5125759840011597},\n",
       " {'label': 'LABEL_0', 'score': 0.5067186951637268},\n",
       " {'label': 'LABEL_0', 'score': 0.5139454007148743},\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"xlm-roberta-base\")\n",
    "classifier(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca72362",
   "metadata": {},
   "source": [
    "# Huggingface Text Classification Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ceb720f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0a2611c093b6474c\n",
      "Found cached dataset text (/home/sumire/.cache/huggingface/datasets/text/default-0a2611c093b6474c/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee8db2595744435b8a2556673bcc98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/sumire/.cache/huggingface/datasets/text/default-0a2611c093b6474c/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c/cache-53c785a19aaad065.arrow\n",
      "Loading cached processed dataset at /home/sumire/.cache/huggingface/datasets/text/default-0a2611c093b6474c/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c/cache-b49de0a535926365.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'labels': ClassLabel(names=['0', '1'], id=None)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from datasets import load_dataset\n",
    "\n",
    "imdb = load_dataset(\"imdb\")\n",
    "\"\"\"\n",
    "hon_data_path = \"/home/sumire/thesis/LLM_Contextual_Prompt_MT/data/contrastive-controlled-mt/IWSLT2022/data/\"\n",
    "\n",
    "data_files = { \"train\": hon_data_path+\"modified/train_en-ja.ja\", \"test\": hon_data_path+\"modified/test_en-ja.ja\"}\n",
    "dataset = load_dataset(\"text\", data_files=data_files)\n",
    "\n",
    "# Add labels\n",
    "train_labels = [sent.split(\", \")[1] for sent in dataset[\"train\"][\"text\"]]\n",
    "test_labels = [sent.split(\", \")[1] for sent in dataset[\"test\"][\"text\"]]\n",
    "\n",
    "dataset[\"train\"]=dataset[\"train\"].add_column(\"labels\", train_labels)\n",
    "dataset[\"test\"]=dataset[\"test\"].add_column(\"labels\", test_labels)\n",
    "\n",
    "#dataset = dataset.cast_column('labels', ClassLabel(num_classes=2, names=[\"Formal\", \"Informal\"]))\n",
    "dataset = dataset.class_encode_column('labels')\n",
    "dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15bc6bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '私のメールアドレスはその時には無効になっていて使えないので、伝えたくないですが。, 0', 'labels': 0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imdb[\"test\"][0]\n",
    "dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc3eb3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/sumire/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/sumire/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/sumire/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/sumire/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/sumire/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "598dda98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples[\"text\"][:10]\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\"\"\"\n",
    "def preprocess_function(data):\n",
    "    inputs = [sent.split(\", \")[0] for sent in data[\"text\"]]\n",
    "    #inputs = [kshot + sent + ' = ' for doc in data[\"doc\"] for sent in doc[\"en\"] ][:50]\n",
    "    return tokenizer(inputs, truncation=True, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db929e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/sumire/.cache/huggingface/datasets/text/default-0a2611c093b6474c/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c/cache-e3fc394d26affe85.arrow\n",
      "Loading cached processed dataset at /home/sumire/.cache/huggingface/datasets/text/default-0a2611c093b6474c/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c/cache-27bc438f2a4703e9.arrow\n"
     ]
    }
   ],
   "source": [
    "#tokenized_imdb = imdb.map(preprocess_function, batched=True)\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c20db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "529b5988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ace2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    print (predictions, labels)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\"\"\"\n",
    "def compute_metrics(eval_preds):\n",
    "    \n",
    "    preds, labels = eval_preds\n",
    "    #eval_preds[1] = [label for label in data[\"labels\"]]\n",
    "    #preds = eval_preds[1]\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    f1 = evaluate.load(\"f1\")\n",
    "    \n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    result = {}\n",
    "    result[\"accuracy\"] = accuracy.compute(predictions=preds, references=labels)\n",
    "    result[\"f1\"] = f1.compute(predictions=preds, references=labels)\n",
    "    print (result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21191d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"formal\", 1: \"informal\"}\n",
    "label2id = {\"formal\": 0, \"informal\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90c4f791",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/sumire/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"formal\",\n",
      "    \"1\": \"informal\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"formal\": 0,\n",
      "    \"informal\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/sumire/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/pytorch_model.bin\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id)\n",
    "#model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\", num_labels=2, id2label=id2label, label2id=label2id)\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "499c967a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 2000\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 250\n",
      "  Number of trainable parameters = 66955010\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:26, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.167770</td>\n",
       "      <td>{'accuracy': 0.9570707070707071}</td>\n",
       "      <td>{'f1': 0.9573221757322177}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.168956</td>\n",
       "      <td>{'accuracy': 0.9587542087542088}</td>\n",
       "      <td>{'f1': 0.958927074601844}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1188\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9570707070707071}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9573221757322177}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': {'accuracy': 0.9570707070707071}, 'f1': {'f1': 0.9573221757322177}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to my_awesome_model/checkpoint-125\n",
      "Configuration saved in my_awesome_model/checkpoint-125/config.json\n",
      "Model weights saved in my_awesome_model/checkpoint-125/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_model/checkpoint-125/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_model/checkpoint-125/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1188\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9587542087542088}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.958927074601844}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': {'accuracy': 0.9587542087542088}, 'f1': {'f1': 0.958927074601844}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to my_awesome_model/checkpoint-250\n",
      "Configuration saved in my_awesome_model/checkpoint-250/config.json\n",
      "Model weights saved in my_awesome_model/checkpoint-250/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_model/checkpoint-250/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_model/checkpoint-250/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from my_awesome_model/checkpoint-125 (score: 0.16776955127716064).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=250, training_loss=0.2471763153076172, metrics={'train_runtime': 26.7555, 'train_samples_per_second': 149.502, 'train_steps_per_second': 9.344, 'total_flos': 147990921936000.0, 'train_loss': 0.2471763153076172, 'epoch': 2.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./hon_distribert\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7435b478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1188\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.9688552188552189}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9687763713080169}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': {'accuracy': 0.9688552188552189}, 'f1': {'f1': 0.9687763713080169}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.10766708105802536,\n",
       " 'eval_accuracy': {'accuracy': 0.9688552188552189},\n",
       " 'eval_f1': {'f1': 0.9687763713080169},\n",
       " 'eval_runtime': 2.7435,\n",
       " 'eval_samples_per_second': 433.021,\n",
       " 'eval_steps_per_second': 27.337,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae96a8",
   "metadata": {},
   "source": [
    "### Findings\n",
    "1. \"distilbert-base-uncased\" won't give the problem that ValueError: Expected input batch_size (1440) to match target batch_size (16), but \"xlm-base\" does\n",
    "2. remove_column _traom ?? gives the problem that eval_preds does not hand over the labels,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
