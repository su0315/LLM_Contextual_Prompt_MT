
generic:
  data_path: /home/sumire/thesis/LLM_Contextual_Prompt_MT/data/iwslt_hf/
  #src_lang: en
  tgt_lang: zh
  #src_context: 0
  #tgt_context: 0
  #dropout: 0.0
  #speaker: False
  #random_context: False
  #tag: False
  #output_dir: "./results/" # Modify here
  batch_size: 8
  model_checkpoint : /mnt/data-poseidon/sumire/hf_llama
  k : 4
  prompt_talk_id : 1548
  max_new_tokens : 64 #128 
  max_length : 512 #512 # 512 # 272 should be okay for k = 3# 313 should be ok for k=4
  cfg_name : llama-zh-1-1
