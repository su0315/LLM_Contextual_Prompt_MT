# LLM_Contextual_Prompt_MT
The updated conda environment can be created by ```llm_mt3.yaml``` 

To evaluate MT models, run
```
python main/eval_mt.py --cfg /path/to/config/file
```

For example, to evaluate 2-1 xglm model in Japanese, run
```
python main/eval_mt.py --cfg path/to/LLM_Contextual_Prompt_MT/main/config/xglm/ja/2-1.yaml
```
